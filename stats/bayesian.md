# 베이지안 통계 맛보기 (miika 세미나)  

### 통계
- 설명 DESCRIPTIVE
  - 데이터를 설명하는 것 
    - 하루 평균 이용자가 얼마나 되는가? 
- 추론 INFERENCE
  - 데이터로 결론을 내는 것
    - A 서비스의 사용자가 B 서비스의 사용자보다 구매력이 높다.
- 통계적인 절차를 바탕으로 결론을 내더라도 **반례**가 존재할 수 있다
  - 이러한 반례가 얼마나 등장할 수 있을까? > 통계적인 의사결정에 존재하는 불확실성 
- 통계는 이 불확실성을 **확률**의 형태로 측정한다

### 확률
- 고전 정의: 확률을 대상의 본질로부터 추론
  - 주사위의 본질은 1-6까지의 숫자가 같은 면적으로 존재한다는 것. 굉장히 상식적이고 논리적 > 면적 대 면적의 비율
    - 길이를 계산해서 길이를 비교하고
    - 면적을 계산대서 면적을 비교
      - 1:1 사각형 안에 그려진 원안에 점이 들어갈 확률 
- 미심쩍은 부분
  - 주사위 1이 나올 확률과 6이 나올 확률은 어떻게 같은지 알지?
  - 케빈이 내일 커밋 안할 확률?


### 확률을 바라보는 관점에 따라 통계학은 두 개의 세력으로 나뉜다
- 객관적인 확률 : **"빈도주의 통계"** 
  - 반복해서 시행했을 때 발생한 상대적인 빈도수 
  - fixed, not a random
  - 반복적으로 계속 시행하다보면 실제 확률 값으로 수렴할 것이다!
  - 즉, 어떤 값인지 잘 모르지만, 변수는 아니다.
  - 주사위를 1000번 던졌을 때 6이 나올 확률은? 
  - 베이지안통계와 완벽하게 대치되는 개념은 아님 
  - 데이터가 많아지면 결국 두 개념은 만나게 되어있음 
- 주관적인 확률 : **"베이지안 통계"**
  - 결과를 얼마나 믿을 수 있는지 신뢰하는 정도
  - random
  - 처음에 가지고 있든 믿음(Prior)을 데이터를 바탕으로 수정한다(posterior)
  - 내가 가지고 있는 정보를 바탕으로 내가 생각했던 확률을 수정한다. 
  - 즉, 모르는 것은 모두 변수다. 
  - 내가 이 주사위를 얼마나 믿을 수 있을까? 뭔가 일반적인 주사위는 아니겠지!!
  - 어떤 타자의 타율이 0.5라고 하면 안믿을 것. 원래 0;2-3 정도 되어야하는 게 아닌가? > 일반적으로 상식선으로 생각했을 때의 선이 있는것(사전믿음) > 여기에 데이터를 추가해서 업데이트를 하는 것 
- 확률을 조금씩 수정, 수치를 맞춰가면서 확률을 조정 > 데이터를 바탕으로 확률을 업데이트! 


### 몬티 홀 문제 


### 확률에 대한 관점의 차이가 통계에 대한 접근 방식을 바꾼다
- 빈도주의 통계
  - 평균키가 정확히 얼마인지는 모르지만 일단 고정된 상수값이다
  - 전세계 모든 사람들의 키를 잴 수 없으니, 전세계 곳곳에서 **고르게!** 샘플을 추출 
    - 샘플링을 어떻게 하면 적은 비용으로 정확한 값을 얻을 수 있을까?
  - 샘플로 추출한 사람들의 평균키를 잰다.
  - **하지만 과연 고르게 뽑았을까?**
  
- 베이지안 통계 
  - 평균키가 얼마인지 모른다. 모르니까 변수!
  - (PRIOR) 이전 연구자료를 토대로 대략적인 평균키 분포를 생각해본다
    - 가설을 계속 세움 
    - 모르는건 모르는대로 냅둠
    - 아는건 확실하게 업데이트 
  - (POSTERIOR) 추출한 샘플 정보를 반영하여 분포를 업데이트함. 
    - 분포의 평균값이 평균 키에 대한 예측값이 된다.
    - 변수이므로 정확히는 모르지만, 평균키를 추정할 수 있는 분포를 알 수 있음 
  - **하지만 뇌피셜 아니냐? **

### 구간 추정: 신약이 환자들에게 효과가 있을 확률 구하기 
- 빈도주의 통계
  - 신뢰구간 95%) 효과있을 확률이 70-80%이다. 
  - 동일한 실험을 천번하면 그 중에서 950번의 시험에서 70-80%의 확률로 효과가 있을 것이다. 


### 베이지안 방법론
- 빈도주의: 파라미터는 변하지 않아!
- 베이지안: 데이터에 따라서 파라미터는 변해! 
- 고정된 파라미터가 아니라 분포를 다룬다
- prior > data > posterior 
- 기본적으로 랜덤을 가정 
- 발생할수있는 모든 고객(=데이터)의 변동은 모델에 맡기자! 
- 사전, 사후가 같은 종류의 분포여야함 

- 장점
  - 불확실성을 더 잘 반영
  - 기존에 알고있던 정보를 모형에 쉽게 통합할 수 있음
    - 이전 연구 결과, 널리 알려진 상식 
- 단점
  - 모형이 복잡해질 경우 구현하기 어렵고, 연산이 너무 무거움
  - 대용량 데이터에 적용하기 어려웠음
  - 데이터가 부족하다면 prior의 영향을 많이 받게 된다. 
    - 연구자료가 사이비네!
- 하지만 최근들어 활용사례 많아짐
  - 방법론 개선
  - 하드웨어 발전
  - 모델링 사용성 개선 - probabilisic programming language 발전 (PyMC4, tensor의 베이지만관려모듈) 

즉, 사람이 하고 있는 논리회로를 수학적으로 풀어낸 것. 




